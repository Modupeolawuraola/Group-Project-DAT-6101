---
  title: "Linear Model LM - Predicting Bike Sharing Demand in the Cities"
author: "Modupeola Fagbenro, Crystal Kao, Guruksha Gurnani, Shanun Randev"
# date: "today"
date: "`r Sys.Date()`"
output:
  html_document:
  code_folding: hide
number_sections: false
toc: yes
toc_depth: 3
toc_float: yes
pdf_document:
  toc: yes
toc_depth: '3'
---
  #Reading CSV file and Displaying Data Dimensions
  
  ```{r, setup= FALSE} 
#Loading libraries
library(tidyverse)
library(psych)
library(ggthemes)
library(ggplot2) #for data visualization
library(dplyr) #for data manipulation
library(tidyr) #for tidying the data
library(corrgram)
library(lubridate)
library(caret)
library(corrplot)
library(leaps)
library(bestglm)
library(rpart)

#Reading the CSV file into data frame
train_data <- read.csv('C:/Users/Asus/OneDrive/Desktop/train_6101.csv', stringsAsFactors = FALSE)
test_data <- read.csv('C:/Users/Asus/OneDrive/Desktop/test_6101.csv', stringsAsFactors =  FALSE)

## Getting Data Frame dimensions
#displaying shape, number of columns, rows and first few rows of the data set
head(train_data)
nrow(train_data)  # Number of rows, 10866
ncol(train_data)  # Number of columns, 12

#Basic information about Data Frame
str(train_data)
```

```{r summary}
summary(train_data) #summary statistics for the data frame
```

```{r , include='FALSE'}
describe(train_data)
```
```{r , include='FALSE'}
str(train_data)
```


# ATTRIBUTES OF DATA:
- date_time: records time and date
- season : season (1:spring, 2:summer, 3:fall, 4:winter)
- holiday : whether day is holiday or not 
- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.
+ weathersit : 
  - 1: Clear, Few clouds, Partly cloudy
- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)
- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)
- hum: Normalized humidity. The values are divided to 100 (max)
- windspeed: Normalized wind speed. The values are divided to 67 (max)
- casual: count of casual users
- registered: count of registered users
- cnt: count of total rental bikes including both casual and registered

### The goal of normalization is to transform features to be on a similar scale. This improves the performance and training stability of the model.

#  Conducting Univariate Analysis 


```{r plot1, echo= 'FALSE'}
ggplot(train_data, aes(temp, count)) + geom_point(alpha = 0.3) + theme_bw() +
  labs(title = "Number of Bikers by Temperature") +
  xlab("Temperature (Celcius)") +
  ylab("Number of Bikers")
```

```{r plot2, echo='FALSE'}

ggplot(train_data, aes(humidity, count)) + geom_point(alpha = 0.3) + theme_bw() +
  labs(title = "Number of Bikers by Humidity") +
  xlab("Humidity (%)") +
  ylab("Number of Bikers")

```
Observations:
  - Every time a bike is shared, the temperature is noted
- Most people won't rent a bike when it is too hot or too cold. More bikes are rented when the temperature is pleasant.
- A high number of bikes are rented when the temperature is around 16 degree celsius and 26 degree celsius.



##When do casual bikers increase the most?

```{r casual bikers, echo= 'FALSE'}
ggplot(train_data, aes(casual, temp))+ geom_point() + theme_light() +
  labs(x = "Number of Casual Bike Users", 
       y = "Temperature (celcius)",
       title = "Casual Bikers by Temperature")
```

Observation: 
- Temp and atemp have a positive linear relation
- Correlation is 0.99
- 0 correlation doesn't mean no relation, it means no linear relation
- We would need to see the plot as well and not rely simply on correlation

##Showing Correlation Heatmap among the Numeric Virables 

```{r, Correlation V2}
library(dplyr)
numeric_train_data <- train_data %>% select_if(is.numeric)
cor_matrix <- cor(numeric_train_data)

# Create the correlation plot
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 0.7)

```
temp and atemp have high correlation. Registered and count have high correlation also.



### Plotting number of bikes rentend across four seasons

```{r Categorical Data vs Continuous Data, echo= 'FALSE'}
library(ggplot2)

#Create a joint scatter plot for 'temp' vs 'atemp'
train_data$season <- as.factor(train_data$season)

# Create a box plot for 'cnt' by 'season'
ggplot(train_data, aes(x = season, y = count, fill = season, group = season)) +
  geom_boxplot() +
  labs(title = "Total # Bikes Rented By Season") +
  scale_fill_brewer(palette = "Set2") +
  xlab("Season") +
  ylab("Total # Bikes Rented")

```
Observation:
  - The cant column is an important column for analysis and the outliers are good for the business because we are working with Bike Sharing Data. So, we will not treat them.


###Feature Selection for modeling  

```{r Feature Selection, include = FALSE}
train_data$datetime <- as.POSIXct(train_data$datetime)


extract_feature <- function(df) {
  df <- df %>%
    mutate(
      year = year(datetime),
      day = day(datetime),
      month = month(datetime),
      hour = hour(datetime),
      dayofweek = wday(datetime) - 1  
    )
  
  return(df)
}


train_data$weather <- as.factor(train_data$weather)



train_data <- extract_feature(train_data)

print(train_data)
```

##All Rentals by Date

```{r Rentals by Date}
df_2011 <- train_data %>% filter(year(datetime) == 2011)
df_2012 <- train_data %>% filter(year(datetime) == 2012)


ggplot() +
  geom_line(data = df_2011, aes(x = datetime, y = count, color = "2011"), size = 1) +
  geom_line(data = df_2012, aes(x = datetime, y = count, color = "2012"), size = 1) +
  scale_color_manual(values = c("2011" = "navy", "2012" = "brown")) +
  labs(x = "Date", y = "Rental Count", title = "2011 and 2012 Rentals") +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_datetime(date_labels = "%Y-%m-%d", date_breaks = "1 month") +
  guides(color = guide_legend(title = "Year"))

```
## Linear Model

```{r Linear Model}

train_data <- train_data %>% select(-datetime)


training_df <- train_data[, !colnames(train_data) %in% c("casual","registered")]


lm_model <- lm(count ~ ., data = training_df)

print(summary(lm_model))




test_data <- extract_feature(test_data)

datetime <- test_data$datetime



test_data <- test_data %>% select(-datetime)

```
```{r}
par(mfrow = c(2,2))
plot(lm_model, which = c(1,2,3))
```
In the residuals vs fitted plot, the variance of residuals increased as the values increased. So we tested a log transformation.
```{r}
lm_model2 <- lm(log(count) ~ ., data = training_df)
summary(lm_model2)
```

```{r}
par(mfrow = c(2,2))
plot(lm_model2, which = c(1,2,3))
```
There is no longer any non constant variance. The Q-Q plot also is better here because there are no curving tails.

## Model Selection
```{r}
lm_model3 <- lm(log(count) ~ .-holiday -day, data = training_df) # no holiday and day
anova(lm_model3,lm_model2)

```
There's no evidence that including holiday and day improves the model's fit.

```{r}
summary(lm_model3)
anova(lm_model3)
```
This means that removing any more variables would reduce model fit
.
```{r}
par(mfrow = c(2,2))
plot(lm_model3, which = c(1,2,3))
```

Which variables are useful for predicting the number of bikes used in an hour?
  All variables other than holiday and day.



How does temperature affect the number of bikes in use?
  The graphs show bikers increase with higher temperatures. In the model, we also see a slight increase in the number of bikers when temperature increases.


## Logit Model
SMART Question 4: Can we estimate when it is a holiday depending on other bikeshare factors?
  
  ```{r}
logclean = training_df
logclean$y = logclean[,2] # renaming holiday to y
logclean = logclean[,-2] # removing holiday
logclean = logclean[,-5] # removing atemp
logclean = logclean[,-8] # removing year
logclean = logclean[,-9] # removing month
logclean = logclean[,-9] # removing hour
logclean = logclean[,-9] # removing dayofweek

#convert columns into factors
logclean$workingday = factor(logclean$workingday)
logclean$y <- ifelse(logclean$y == 1,TRUE,FALSE)
logclean$y = factor(logclean$y)

str(logclean)
```

```{r bestglm}

log.bestglm <- bestglm(Xy = logclean, family = binomial,
                       IC = "AIC",                
                       method = "exhaustive")
summary(log.bestglm)
log.bestglm$BestModels
summary(log.bestglm$BestModels)
```

The best model has AIC of 2082, with only variables `season`, `windspeed` and `workingday`.  Although this AIC is quite high, this is the model that has the best fit for predicting if it's a holiday.




```{r}

library(ggplot2)
library(ISLR)
p1 <- ggplot(training_df,aes(temp, count, color = season))
print(p1 + geom_point(size = 4))

```




#decision tree


```{r}

table(training_df$workingday)

copied_df = data.frame(training_df)



library(rpart)
library(rpart.plot)
library(randomForest)




copied_df = copied_df[, -c(1,4)]

train_percentage <- 0.8

# Generate random indices for the training set
indices <- sample(1:nrow(copied_df), size = round(train_percentage * nrow(copied_df)), replace = FALSE)

# Create the training set
train_set <- copied_df[indices, ]

# Create the testing set
test_set <- copied_df[-indices, ]


train_features <- train_set[, -which(names(train_set) == "temp")]
train_target <- train_set$temp

# Separate features and target in the testing set
test_features <- test_set[, -which(names(test_set) == "temp")]
test_target <- test_set$temp


tree <- rpart(train_target ~ .,method = 'anova', data = train_features,minsplit = 5)

predictions <- predict(tree, newdata = test_features)

rmse <- sqrt(mean((test_target - predictions)^2))

# Display the RMSE
print(paste("Root Mean Squared Error:", rmse))


printcp(tree)



prp(tree)


```

```{r}

rf.model <- randomForest(train_target ~ ., method = 'anova', data = train_features)


predictions_rfm <- predict(rf.model, newdata = test_features)

rmse_rfm <- sqrt(mean((test_target - predictions_rfm)^2))

print(rf.model)

print(paste("Root Mean Squared Error for rfm:", rmse_rfm))


print(rmse_rfm)
varImpPlot(rf.model)


```



