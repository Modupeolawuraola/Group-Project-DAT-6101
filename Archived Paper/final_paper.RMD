---
title: "Predicting Bike Sharing Demand in the Cities"
author: "Modupeola Fagbenro, Crystal Kao, Guruksha Gurnani, Shanun Randev"
# date: "today"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---
# Introduction 
## Background of the study
The given data set encompasses information about bike sharing, a rapidly growing sustainable mode of transportation. Bike-sharing systems have been gaining more popularity in urban areas than in rural ones due to the convenience and ease of traveling. This eco-friendly system allows individuals to rent bikes for short periods typically on an hourly basis, making them an efficient choice of commute, and leisure and reducing environmental impact.
Our data spans over 10,000 rows across 15 columns– season, Holiday, working day, Weather, Temperature, Atemp, Humidity, windspeed, casual, registered, count, datetime.

As a direct quote from the data source: 

  ``Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city…"

The data is specifically collected from the Capital Bikeshare program in Washington, D.C for 2011-2012.


## Problem Statement
In bustling urban centers characterized by heavy traffic and relatively short distances between points of interest, bike sharing has emerged as a viable alternative mode of transportation. Bike sharing allows individuals to conveniently rent bicycles from designated stations, without the requirement of returning them to the same station. Instead, there are numerous drop-off locations scattered throughout the city, offering increased flexibility in returning bicycles.

## Research Aim and Objectives 
The objective of this research is to check factors that can influence Bike Sharing:

1.	Checking Number of Urban Rentals Higher casual or registered population density in urban areas typically makes bike sharing more appealing due to shorter distances between destinations and increased demand for alternative transportation options.
2.	Weather Conditions: Weather, such as temperature, humidity, or extreme heat, can impact bike sharing. Cities with more favorable weather conditions may see higher bike-sharing usage.
3.	High-year Rentals: The increase in bikes year in and year out can be a result of good weather conditions or an increase in awareness of alternative means of transportation such as bike sharing.

## Research SMART Questions
Specific Measurable Achievable Relevant and Time-Bound Questions (SMART):
Here are the SMART Questions, our analysis aims to answer:

1.	Which variables are useful for predicting the number of bikes used in an hour?
2.	How does temperature affect the number of bikes in use?
3.	When do casual bikers increase the most?

Applying the SMART framework to our questions allows us to set clear objectives, measure progress, and ensure that the analysis provides meaningful insight for decision-makers/stakeholders in the context of bike sharing.

## Dataset Fields

-	Datetime – The hour, date, and timestamp of each observation.
-	Season: Categorical variable indicating the season, which can affect bike usage (e.g., 1-spring, 2-summer, 3-fall, 4-winter).
-	Holiday: It’s binary variable indicating whether it's a holiday (1 for yes, 0 for no)
-	Working Day: It's a binary variable indicating whether it's a working day (1 for yes, 0 for no).
+	Weather: Categorical variable representing different weather conditions, influencing bike ridership (e.g., clear, cloudy, rainy).
    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy
    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
-	Temperature (temp): Temperature in Celsius, affecting user preferences for bike rides.
-	Atemp : "Feels Like" Temperature (atemp): This column represents the "feels like" temperature, which takes into account factors such as wind chill and humidity to provide a more accurate perception of temperature. It can affect user comfort and, consequently, bike usage.
-	Humidity: Humidity level, which can impact the comfort of cycling.
-	Windspeed: Windspeed, another weather-related factor that affects bike riding conditions.
-	Casual: The number of casual (non-registered) bike rentals.
-	Registered: The number of registered bike rentals, indicating regular users of the bike sharing system.
-	Count: The total count of bike rentals, which is the sum of casual and registered rentals, serving as the primary target variable for analysis and prediction.

Based on the above information, this data set allows us to explore how different factors including but not limited to weather conditions, time of the day, and humidity can impact bike-sharing trends and use these insights to improve bike-sharing systems.

# Exploratory Data Analysis and Methodology
Performing exploratory data analysis (EDA) on a bike-sharing dataset is an essential step to gain insights and understand the data before diving into more advanced analyses. Here's a step-by-step guide to performing EDA on a bike-sharing dataset and what methods we used:

## EDA Steps Conducted:

1.	**Data Collection**: Start by obtaining the bike-sharing dataset from Kaggle. https://www.kaggle.com/competitions/bike-sharing-demand/data
2.	**Data Loading**: Import the dataset into R studio data analysis environment. 

```{r, warning=FALSE} 
#Reading the CSV file into data frame
train_data <- read.csv('train.csv', stringsAsFactors = FALSE)
```

3.	**Load Useful Packages**:  The packages used in this analysis include: tidyverse, psych, ggthemes, ggplot2, dplyr, tidyr, corrgram, lubridate, caret, corrplot.
```{r, setup= FALSE, warning=FALSE} 
#Loading libraries
library(tidyverse)
library(psych)
library(ggthemes)
library(ggplot2) #for data visualization
library(dplyr) #for data manipulation
library(tidyr) #for tidying the data
library(corrgram)
library(lubridate)
library(caret)
library(corrplot)
```

4.	**Data Overview**: Check the first few rows of the dataset to understand its structure and the kind of information it contains. Next check the data types of each column (e.g., categorical datatypes and numerical datatypes) to ensure they are correctly interpreted. Finally, inspect the columns (variables) in the dataset and their names.
```{r, setup= FALSE, warning=FALSE} 
 
## Getting Data Frame dimensions
#displaying shape, number of columns, rows and first few rows of the data set
head(train_data)
nrow(train_data)  # Number of rows, 10866
ncol(train_data)  # Number of columns, 12

#Basic information about Data Frame
str(train_data)
```

```{r}
describe(train_data)
```

5.	**Data Cleaning**: Handle missing data by either imputing missing values or removing rows/columns with missing data. This data file luckily did not include any missing values or rows. 
6.	**Summary Statistics**: Calculate summary statistics like mean, median, standard deviation, and percentiles for numerical variables. This provides an initial understanding of the data distribution. For categorical variables, calculate frequency counts and proportions.
```{r summary}
summary(train_data) #summary statistics for the data frame
```

7.	**Data Visualization**: Create visualizations to gain insights into the data. Some plots we used include scatterplots, box plots, bar charts, and correlation matrices. 
```{r, echo=FALSE}
ggplot(train_data, aes(temp, count)) + geom_point(alpha = 0.3) + theme_bw() +
  labs(title = "Number of Bikers by Temperature") +
  xlab("Temperature (Celcius)") +
  ylab("Number of Bikers")
```

```{r, echo=FALSE}

ggplot(train_data, aes(humidity, count)) + geom_point(alpha = 0.3) + theme_bw() +
  labs(title = "Number of Bikers by Humidity") +
  xlab("Humidity (%)") +
  ylab("Number of Bikers")

```

```{r, echo=FALSE}
numeric_train_data <- train_data %>% select_if(is.numeric)
cor_matrix <- cor(numeric_train_data)

# Create the correlation plot
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 0.7)

```

```{r, echo=FALSE}

#Create a joint scatter plot for 'temp' vs 'atemp'
train_data$season <- as.factor(train_data$season)

# Create a box plot for 'cnt' by 'season'
ggplot(train_data, aes(x = season, y = count, fill = season, group = season)) +
  geom_boxplot() +
  labs(title = "Total # Bikes Rented By Season") +
  scale_fill_brewer(palette = "Set2") +
  xlab("Season") +
  ylab("Total # Bikes Rented")

```


8.	**Distributions and Patterns**: Examine the distribution of the target variable(s) (e.g., bike rentals) and potential predictor variables. For this analysis, we looked at bikers by temperature, bikers by humidity, and bikers by season, which will all be shown in the results section as they pertain to our SMART questions.

# Changes Made After EDA
After doing some EDA, some of our questions changed to adhere more to what made more sense for our data to answer and focus in on answering more pointed questions. For example, one of our original questions was which variable has the highest effect on the count of the number of bikes used in a day? However, due to the way the data is collected and the purpose of the dataset, it made more sense to change the question to which variables are useful for predicting the number of bikes used in an hour? Since the data is collected hourly and creating a model instead of looking for a specific variable made more sense. The model can be used to predict future bike sharing rates. 

# Model Selection and Hypothesis Testing
Since we were interested in learning about which variables influence the number of bikers in a given hour, we wanted to create a linear regression model. Before doing so, we needed to format our data appropriately. We created new fields based on the ‘Datetime’ column to split out the year, day, month, hour and day of the week. ‘Season’ and ‘weather’ are categorical variables and were represented using dummy variables.

```{r}
train_data$datetime <- as.POSIXct(train_data$datetime)


extract_feature <- function(df) {
  df <- df %>%
    mutate(
      year = year(datetime),
      day = day(datetime),
      month = month(datetime),
      hour = hour(datetime),
      dayofweek = wday(datetime) - 1  
    )
  
  return(df)
}


train_data$weather <- as.factor(train_data$weather)



train_data <- extract_feature(train_data)

```

We first started out by running a linear model on the data with ‘count’ as the dependent variable and all other available variables as the predictors (this is considered Model 1). However, we excluded ‘registered’ and ‘casual’ because they sum up to the ‘count’. 
```{r}

train_data <- train_data %>% select(-datetime)


training_df <- train_data[, !colnames(train_data) %in% c("casual","registered")]


lm_model <- lm(count ~ ., data = training_df)

print(summary(lm_model))

```

```{r}
par(mfrow = c(2,2))
plot(lm_model, which = c(1,2,3))
```

Based on the results of the residuals vs fitted plot, the variance of residuals increased as the values increased. 

A log transformation was considered to see if there was a model with more constant variance. Because of this, we also ran a version of the model with a log transformation on the ‘count’ field to see if the normality assumption would be more reasonable on the log scale (this is considered Model 2).
```{r}
lm_model2 <- lm(log(count) ~ ., data = training_df)
summary(lm_model2)
```

```{r}
par(mfrow = c(2,2))
plot(lm_model2, which = c(1,2,3))
```

With this new model, the residuals vs fitted plot no longer increased as the values increased, and the qq-plot also shows that normality is a reasonable assumption. Noticing that ‘holiday’ and ‘day’ were not statistically significant in this model based on the t-tests, we created another model based on the log transformed model where ‘holiday’ and ‘day’ were taken out (this model is considered Model 3). 
```{r}
lm_model3 <- lm(log(count) ~ .-holiday -day, data = training_df) # no holiday and day

```

```{r}
par(mfrow = c(2,2))
plot(lm_model3, which = c(1,2,3))
```

An ANOVA was then run on this model with the following hypotheses: 

    Null Hypothesis: Model 3 is a reasonable fit
    
    Alternative Hypothesis: Model 2 is a reasonable fit
```{r}
anova(lm_model3,lm_model2)
```

The p-value is greater than 0.05, so we do not reject the null hypothesis, which means Model 3 is adequate to model the rentals. There's no evidence that including ‘holiday’ and ‘day’ improves the model's fit.

An ANOVA was also run on Model 3 to confirm that all the variables included have statistical significance even after adjustment for the other variables. If any of the variables were not statistically significant, we would have continued our model selection by removing those variables. However, all the variables were statistically significant, so we continued our analysis with Model 3.

```{r}
summary(lm_model3)
anova(lm_model3)
```

# Results

#Conclusions/Next Steps








```{r plot1, echo= 'FALSE'}
ggplot(train_data, aes(temp, count)) + geom_point(alpha = 0.3) + theme_bw() +
  labs(title = "Number of Bikers by Temperature") +
  xlab("Temperature (Celcius)") +
  ylab("Number of Bikers")
```

```{r plot2, echo='FALSE'}

ggplot(train_data, aes(humidity, count)) + geom_point(alpha = 0.3) + theme_bw() +
  labs(title = "Number of Bikers by Humidity") +
  xlab("Humidity (%)") +
  ylab("Number of Bikers")

```
Observations:
- Every time a bike is shared, the temperature is noted
- Most people won't rent a bike when it is too hot or too cold. More bikes are rented when the temperature is pleasant.
- A high number of bikes are rented when the temperature is around 16 degree celsius and 26 degree celsius.



##When do casual bikers increase the most?

```{r casual bikers, echo= 'FALSE'}
ggplot(train_data, aes(casual, temp))+ geom_point() + theme_light() +
  labs(x = "Number of Casual Bike Users", 
       y = "Temperature (celcius)",
       title = "Casual Bikers by Temperature")
```

Observation: 
- Temp and atemp have a positive linear relation
- Correlation is 0.99
- 0 correlation doesn't mean no relation, it means no linear relation
- We would need to see the plot as well and not rely simply on correlation

##Showing Correlation Heatmap among the Numeric Virables 

```{r, Correlation V2}
library(dplyr)
numeric_train_data <- train_data %>% select_if(is.numeric)
cor_matrix <- cor(numeric_train_data)

# Create the correlation plot
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 0.7)

```
temp and atemp have high correlation. Registered and count have high correlation also.



### Plotting number of bikes rentend across four seasons

```{r Categorical Data vs Continuous Data, echo= 'FALSE'}
library(ggplot2)

#Create a joint scatter plot for 'temp' vs 'atemp'
train_data$season <- as.factor(train_data$season)

# Create a box plot for 'cnt' by 'season'
ggplot(train_data, aes(x = season, y = count, fill = season, group = season)) +
  geom_boxplot() +
  labs(title = "Total # Bikes Rented By Season") +
  scale_fill_brewer(palette = "Set2") +
  xlab("Season") +
  ylab("Total # Bikes Rented")

```
Observation:
- The cant column is an important column for analysis and the outliers are good for the business because we are working with Bike Sharing Data. So, we will not treat them.

## Linear Model

```{r Linear Model}


lm_model <- lm(count ~ ., data = training_df)

print(summary(lm_model))

```

```{r}
par(mfrow = c(2,2))
plot(lm_model, which = c(1,2,3))
```
In the residuals vs fitted plot, the variance of residuals increased as the values increased. So we tested a log transformation.
```{r}
lm_model2 <- lm(log(count) ~ ., data = training_df)
summary(lm_model2)
```

```{r}
par(mfrow = c(2,2))
plot(lm_model2, which = c(1,2,3))
```
There is no longer any non constant variance. The Q-Q plot also is better here because there are no curving tails.

## Model Selection
```{r}
lm_model3 <- lm(log(count) ~ .-holiday -day, data = training_df) # no holiday and day
anova(lm_model3,lm_model2)

```
There's no evidence that including holiday and day improves the model's fit.

```{r}
summary(lm_model3)
anova(lm_model3)
```
This means that removing any more variables would reduce model fit
.
```{r}
par(mfrow = c(2,2))
plot(lm_model3, which = c(1,2,3))
```

Which variables are useful for predicting the number of bikes used in an hour?
All variables other than holiday and day.



How does temperature affect the number of bikes in use?
The graphs show bikers increase with higher temperatures. In the model, we also see a slight increase in the number of bikers when temperature increases.
